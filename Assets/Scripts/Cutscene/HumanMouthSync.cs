using System;
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class HumanMouthSync : MonoBehaviour
{
    // TTS: usual
    // PCM: when given data pre-compiled by a file
    public enum Mode
    {
        TTS, PCM
    }

    [System.Serializable]
    public struct PhonemeToName
    {
        public string phoneme;
        public string name;
        public PhonemeToName(string p, string n) { phoneme = p; name = n; }
    }
    [System.Serializable]
    public struct NameToSprite
    {
        public string name;
        public Sprite sprite;
        public NameToSprite(string n, Sprite s) { name = n; sprite = s; }
    }
    public enum Emotion
    {
        None, Happy, Sad, DontSet
    }
    [System.Serializable]
    public struct EmotionToNeutralSprite
    {
        public Emotion emotion;
        public Sprite sprite;
        public EmotionToNeutralSprite(Emotion e, Sprite s) { emotion = e; sprite = s; }
    }

    public Mode mode;
    public PhonemeToName[] phonemeToName;
    private Dictionary<string, string> phonemeToNameReal = new Dictionary<string, string>();
    public NameToSprite[] nameToSprite;
    private Dictionary<string, Sprite> nameToSpriteReal = new Dictionary<string, Sprite>();
    public Emotion emotion;
    public EmotionToNeutralSprite[] emotionToSprite;
    private Dictionary<Emotion, Sprite> emotionToSpriteReal = new Dictionary<Emotion, Sprite>();
    public Renderer mouthItem;
    public int mouthMatIndex;
    public ActualSpeaking speaker;
    // Unity can't animate strings but it can animate non-scene objects, what the heck!!!
    public AudioClip pcmAudioName;
    public Transform pcmAudioSearchRoot;
    public TextAsset pcmLipSyncData; // generated by Rhubarb by DanielSWolf
    private List<Tuple<float, string>> lipSyncDataParsed = new List<Tuple<float, string>>();
    private int lipSyncDataIndex = 0;
    private Dictionary<string, string> rhubarbLetterToMyLetter = new Dictionary<string, string>()
    {
        {"A", ""}, {"B", "ee"}, {"C", "eh"}, {"D", "ah"}, {"E", "oh"},
        {"F", "oo"}, {"G", "f"}, {"H", "l"}, { "X", "" }
    };
    public int framesDelay = 3;
    private Queue<string> phonemeBuffer = new Queue<string>();

    private bool active = false;

    void Start()
    {
        foreach (PhonemeToName x in phonemeToName)
        {
            phonemeToNameReal.Add(x.phoneme, x.name);
        }
        foreach (NameToSprite x in nameToSprite)
        {
            nameToSpriteReal.Add(x.name, x.sprite);
        }
        foreach (EmotionToNeutralSprite x in emotionToSprite)
        {
            emotionToSpriteReal.Add(x.emotion, x.sprite);
        }
    }

    public void Deactivate()
    {
        active = false;
        lipSyncDataParsed.Clear();
    }

    public void Activate()
    {
        active = true;
        lipSyncDataIndex = 0;
    }

    void Update()
    {
        Material mouth = mouthItem.materials[mouthMatIndex];
        if (emotionToSpriteReal.ContainsKey(emotion))
        {
            nameToSpriteReal[""] = emotionToSpriteReal[emotion];
        }
        if (!speaker || !active)
        {
            mouth.SetTexture("_MainTex", nameToSpriteReal[phonemeToNameReal[""]].texture);
            return;
        }
        switch (mode)
        {
            case Mode.TTS:
                phonemeBuffer.Enqueue(speaker.currentPhoneme);
                while (phonemeBuffer.Count >= framesDelay)
                {
                    string ph = phonemeBuffer.Dequeue();
                    mouth.SetTexture("_MainTex", nameToSpriteReal[phonemeToNameReal[phonemeToNameReal.ContainsKey(ph) ? ph : ""]].texture);
                }
                break;
            case Mode.PCM:
                if (!pcmAudioSearchRoot || !pcmLipSyncData) { break; }
                // references to objects in the scene can't be animated.
                AudioSource pcmAudio = pcmAudioSearchRoot.Find(pcmAudioName.name)?.GetComponent<AudioSource>();
                if (!pcmAudio) { break; }
                float pcmTime = pcmAudio.time - ((float)framesDelay / Application.targetFrameRate);
                pcmTime = Mathf.Clamp(pcmTime, 0f, pcmAudio.clip.length);
                if (pcmTime == pcmAudio.clip.length) { Deactivate(); break; }
                if (lipSyncDataParsed.Count == 0)
                {
                    // init
                    foreach (string line in pcmLipSyncData.text.Split('\n'))
                    {
                        string[] pieces = line.Split('\t');
                        if (pieces[0].Trim().Length == 0) { continue; }
                        lipSyncDataParsed.Add(new Tuple<float, string>(
                            float.Parse(pieces[0].Trim()),
                            rhubarbLetterToMyLetter[pieces[1].Trim()]
                        ));
                    }
                }
                while (lipSyncDataIndex + 1 < lipSyncDataParsed.Count
                            && lipSyncDataParsed[lipSyncDataIndex + 1].Item1 < pcmTime)
                {
                    ++lipSyncDataIndex;
                }
                string mouthStr = lipSyncDataParsed[lipSyncDataIndex].Item2;
                mouth.SetTexture("_MainTex", nameToSpriteReal[mouthStr].texture);

                break;
        }
    }
}
